{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7bdab228",
      "metadata": {
        "id": "7bdab228"
      },
      "outputs": [],
      "source": [
        "from sklearn.cluster import AgglomerativeClustering\n",
        "from pytesseract import Output\n",
        "from tabulate import tabulate\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pytesseract\n",
        "import argparse\n",
        "import imutils\n",
        "import cv2\n",
        "from PIL import Image\n",
        "from matplotlib import pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "410e134f",
      "metadata": {
        "id": "410e134f"
      },
      "outputs": [],
      "source": [
        "# PREPROCESS\n",
        "def display(im_path):\n",
        "    dpi = 80\n",
        "    im_data = plt.imread(im_path)\n",
        "\n",
        "    height, width  = im_data.shape[:2]\n",
        "\n",
        "    # What size does the figure need to be in inches to fit the image?\n",
        "    figsize = width / float(dpi), height / float(dpi)\n",
        "\n",
        "    # Create a figure of the right size with one axes that takes up the full figure\n",
        "    fig = plt.figure(figsize=figsize)\n",
        "    ax = fig.add_axes([0, 0, 1, 1])\n",
        "\n",
        "    # Hide spines, ticks, etc.\n",
        "    ax.axis('off')\n",
        "\n",
        "    # Display the image.\n",
        "    ax.imshow(im_data, cmap='gray')\n",
        "\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0d90e9e2",
      "metadata": {
        "id": "0d90e9e2"
      },
      "outputs": [],
      "source": [
        "original_file = 'Images/P00296_B014_page2.jpg'\n",
        "orig = cv2.imread(original_file)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0a1f4fd4",
      "metadata": {
        "id": "0a1f4fd4"
      },
      "source": [
        "## SECONDLY, OCR -- run every contour crop through tesseract OCR engine\n",
        "inspo: https://nanonets.com/blog/ocr-with-tesseract/\n",
        "https://pyimagesearch.com/2022/02/28/multi-column-table-ocr/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "642e1141",
      "metadata": {
        "id": "642e1141"
      },
      "outputs": [],
      "source": [
        "ap = argparse.ArgumentParser()\n",
        "ap.add_argument(\"-i\", \"--image\", required=True,\n",
        "                help=\"path to input image to be OCR'd\")\n",
        "ap.add_argument(\"-o\", \"--output\", required=True,\n",
        "                help=\"path to output CSV file\")\n",
        "ap.add_argument(\"-c\", \"--min-conf\", type=int, default=0,\n",
        "                help=\"minimum confidence value to filter weak text detection\")\n",
        "ap.add_argument(\"-d\", \"--dist-thresh\", type=float, default=25.0,\n",
        "                help=\"distance threshold cutoff for clustering\")\n",
        "ap.add_argument(\"-s\", \"--min-size\", type=int, default=2,\n",
        "                help=\"minimum cluster size (i.e., # of entries in column)\")\n",
        "\n",
        "# args = vars(ap.parse_args())\n",
        "args = vars(ap.parse_args([\"-i\", \"Images/P00296_B014_page2.jpg\", \"-o\", \"output_df.csv\"]))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6ae7248d",
      "metadata": {
        "id": "6ae7248d"
      },
      "outputs": [],
      "source": [
        "# set a seed for our random number generator\n",
        "np.random.seed(42)\n",
        "# load the input image and convert it to grayscale\n",
        "image = cv2.imread(args[\"image\"])\n",
        "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "40b1f220",
      "metadata": {
        "id": "40b1f220"
      },
      "outputs": [],
      "source": [
        "# initialize a rectangular kernel that is ~5x wider than it is tall,\n",
        "# then smooth the image using a 3x3 Gaussian blur and then apply a\n",
        "# blackhat morphological operator to find dark regions on a light\n",
        "# background\n",
        "kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (51, 11))\n",
        "gray = cv2.GaussianBlur(gray, (3, 3), 0)\n",
        "blackhat = cv2.morphologyEx(gray, cv2.MORPH_BLACKHAT, kernel)\n",
        "\n",
        "# compute the Scharr gradient of the blackhat image and scale the\n",
        "# result into the range [0, 255]\n",
        "grad = cv2.Sobel(blackhat, ddepth=cv2.CV_32F, dx=1, dy=0, ksize=-1)\n",
        "grad = np.absolute(grad)\n",
        "(minVal, maxVal) = (np.min(grad), np.max(grad))\n",
        "grad = (grad - minVal) / (maxVal - minVal)\n",
        "grad = (grad * 255).astype(\"uint8\")\n",
        "\n",
        "# apply a closing operation using the rectangular kernel to close\n",
        "# gaps in between characters, apply Otsu's thresholding method, and\n",
        "# finally a dilation operation to enlarge foreground regions\n",
        "grad = cv2.morphologyEx(grad, cv2.MORPH_CLOSE, kernel)\n",
        "thresh = cv2.threshold(grad, 0, 255,\n",
        "                       cv2.THRESH_BINARY | cv2.THRESH_OTSU)[1]\n",
        "thresh = cv2.dilate(thresh, None, iterations=3)\n",
        "cv2.imshow(\"Thresh\", thresh)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "070e1914",
      "metadata": {
        "id": "070e1914"
      },
      "outputs": [],
      "source": [
        "# find contours in the thresholded image and grab the largest one,\n",
        "# which we will assume is the stats table\n",
        "cnts = cv2.findContours(thresh.copy(), cv2.RETR_EXTERNAL,\n",
        "                        cv2.CHAIN_APPROX_SIMPLE)\n",
        "cnts = imutils.grab_contours(cnts)\n",
        "tableCnt = max(cnts, key=cv2.contourArea)\n",
        "\n",
        "# compute the bounding box coordinates of the stats table and extract\n",
        "# the table from the input image\n",
        "(x, y, w, h) = cv2.boundingRect(tableCnt)\n",
        "table = image[y:y + h, x:x + w]\n",
        "\n",
        "# show the original input image and extracted table to our screen\n",
        "cv2.imshow(\"Input\", image)\n",
        "cv2.imshow(\"Table\", table)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ba3d6f83",
      "metadata": {
        "id": "ba3d6f83"
      },
      "outputs": [],
      "source": [
        "# set the PSM mode to detect sparse text, and then localize text in\n",
        "# the table\n",
        "options = \"--psm 6\"\n",
        "results = pytesseract.image_to_data(\n",
        "    cv2.cvtColor(table, cv2.COLOR_BGR2RGB),\n",
        "    config=options,\n",
        "    output_type=Output.DICT)\n",
        "\n",
        "# initialize a list to store the (x, y)-coordinates of the detected\n",
        "# text along with the OCR'd text itself\n",
        "coords = []\n",
        "ocrText = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9b2807d5",
      "metadata": {
        "id": "9b2807d5"
      },
      "outputs": [],
      "source": [
        "# loop over each of the individual text localizations\n",
        "for i in range(0, len(results[\"text\"])):\n",
        "    # extract the bounding box coordinates of the text region from the current result\n",
        "    x = results[\"left\"][i]\n",
        "    y = results[\"top\"][i]\n",
        "    w = results[\"width\"][i]\n",
        "    h = results[\"height\"][i]\n",
        "\n",
        "    # extract the OCR text itself along with the confidence of the text localization\n",
        "    text = results[\"text\"][i]\n",
        "    conf = int(results[\"conf\"][i])\n",
        "\n",
        "    # filter out weak confidence text localizations\n",
        "    if conf > args[\"min_conf\"]:\n",
        "        # update our text bounding box coordinates and OCR'd text, respectively\n",
        "        coords.append((x, y, w, h))\n",
        "        ocrText.append(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "19b81577",
      "metadata": {
        "id": "19b81577",
        "outputId": "0cd93c99-c1a0-4aec-dc50-01b01e2e8ffa"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/sandy/opt/anaconda3/envs/BOEMddiscovery/lib/python3.11/site-packages/sklearn/cluster/_agglomerative.py:1006: FutureWarning: Attribute `affinity` was deprecated in version 1.2 and will be removed in 1.4. Use `metric` instead\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# extract all x-coordinates from the text bounding boxes, setting the y-coordinate value to zero\n",
        "xCoords = [(c[0], 0) for c in coords]\n",
        "\n",
        "# apply hierarchical agglomerative clustering to the coordinates\n",
        "clustering = AgglomerativeClustering(\n",
        "    n_clusters=None,\n",
        "    linkage=\"complete\",\n",
        "    distance_threshold=args[\"dist_thresh\"],\n",
        "    affinity=\"manhattan\")  # Use 'manhattan' metric here\n",
        "clustering.fit(xCoords)\n",
        "\n",
        "# initialize our list of sorted clusters\n",
        "sortedClusters = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "73e6712c",
      "metadata": {
        "id": "73e6712c"
      },
      "outputs": [],
      "source": [
        "# loop over all clusters\n",
        "for l in np.unique(clustering.labels_):\n",
        "    # extract the indexes for the coordinates belonging to the current cluster\n",
        "    idxs = np.where(clustering.labels_ == l)[0]\n",
        "\n",
        "    # verify that the cluster is sufficiently large\n",
        "    if len(idxs) > args[\"min_size\"]:\n",
        "        # compute the average x-coordinate value of the cluster and\n",
        "        avg = np.average([coords[i][0] for i in idxs])\n",
        "        # update our clusters list with the current label and the average x-coordinate\n",
        "        sortedClusters.append((l, avg))\n",
        "# sort the clusters by their average x-coordinate and initialize our data frame\n",
        "sortedClusters.sort(key=lambda x: x[1])\n",
        "df = pd.DataFrame()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1b7c6483",
      "metadata": {
        "id": "1b7c6483"
      },
      "outputs": [],
      "source": [
        "# loop over the clusters again, this time in sorted order\n",
        "for (l, _) in sortedClusters:\n",
        "    # extract the indexes for the coordinates belonging to the current cluster\n",
        "    idxs = np.where(clustering.labels_ == l)[0]\n",
        "\n",
        "    # extract the y-coordinates from the elements in the current cluster, then sort them from top-to-bottom\n",
        "    yCoords = [coords[i][1] for i in idxs]\n",
        "    sortedIdxs = idxs[np.argsort(yCoords)]\n",
        "\n",
        "    # generate a random color for the cluster\n",
        "    color = np.random.randint(0, 255, size=(3,), dtype=\"int\")\n",
        "    color = [int(c) for c in color]\n",
        "\n",
        "    # loop over the sorted indexes\n",
        "    for i in sortedIdxs:\n",
        "        # extract the text bounding box coordinates\n",
        "        (x, y, w, h) = coords[i]\n",
        "        # draw the bounding box surrounding the current element\n",
        "        cv2.rectangle(table, (x, y), (x + w, y + h), color, 2)\n",
        "\n",
        "    # extract the OCR'd text for the current column\n",
        "    cols = [ocrText[i].strip() for i in sortedIdxs]\n",
        "    # construct a df for the data where the first entry in our column serves as the header\n",
        "    currentDF = pd.DataFrame({cols[0]: cols[1:]})\n",
        "\n",
        "    # concatenate *original* data frame with the *current* df (we do this to handle columns that may have a varying number of rows)\n",
        "    df = pd.concat([df, currentDF], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0f15c8de",
      "metadata": {
        "id": "0f15c8de",
        "outputId": "4986c53a-426d-452a-c389-5f406ff278a4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+----+--------+---------+--------+----------+------+--------+-------+--------+-------+------+\n",
            "|    | Test   | care,   | FLOW   | s7s2ie   | #4   | Nor    | vor   | nue    | ELS   | y    |\n",
            "|----+--------+---------+--------+----------+------+--------+-------+--------+-------+------|\n",
            "|  0 | rime   | Sut     | ae     | PERIOD   | near | yout   | 5     | ERIE   | aan   | ‘ss, |\n",
            "|  1 | wide   | SMa     | bce    | OEE      | URE  | 006.6, | EA    | ann    | i     | io   |\n",
            "|  2 | Sang   | SH      | ante   | gage     | OU   | ina    |       | ten    | BE    | ag   |\n",
            "|  3 | BEG    | EARS    |        | OBES     | oy   | OED    |       | HESS   | HEE   | dag  |\n",
            "|  4 | RG     | care    |        | Bee      | aay  | 5      |       | BE     | EE    | ER   |\n",
            "|  5 | esr    | Steir   |        | BR       | TEE  | vor    |       | woe    | BES   | Ege  |\n",
            "|  6 | rg     | re      |        | BSS      | Pa   | gous   |       | tenets | EOD   | bad  |\n",
            "|  7 | PEGE   | SORE    |        | Beg      | OER  | S00,   |       | OME    | BR    | ite  |\n",
            "|  8 | BAM    | SRS     |        | Bea      | Ce   | tan.   |       | EE     | Bel   | Eas  |\n",
            "|  9 | BAS    | Se      |        | RES      | Ga   | HE     |       | ER     | iS    | rig  |\n",
            "| 10 | PAGE   | SES     |        | Ge       | OG   | GE     |       | IRE    | BE    | pa   |\n",
            "| 11 | BSG    | SHES    |        | GS       | Ga   | HEP    |       | IRE    | RED   | be   |\n",
            "| 12 | Sta    | SHOR    |        | GH       | Ge   | HEP    |       | REED   | REG   | gag  |\n",
            "| 13 | PEGE   | SORES   |        | HS       | SHE  | HE     |       | BE     | BEE   | Eee  |\n",
            "| 14 | BS     | SORES   |        |          | pa   | HE     |       | BEE    | HER   | a2   |\n",
            "| 15 | BSG    | Se      |        |          | UE   | HED    |       | RSH    | GH    | ES   |\n",
            "| 16 | Wha    | CH      |        |          | ICR  | HE     |       | HEE    | BEB   | HG   |\n",
            "| 17 | TES    | SHR     |        |          | IG   | EP     |       | eg     | BOE   | Ee   |\n",
            "| 18 | TE     | Se      |        |          | ee   | HEE    |       | HH     | EEE   | bet  |\n",
            "| 19 | HGS    | HORS    |        |          | a    | BES    |       | RE     | HEE   | Ei   |\n",
            "| 20 | Tee    | SH      |        |          | Bu   | Bre    |       | ian    | HES   | EH   |\n",
            "| 21 | THER   | SH      |        |          | GS   | BES    |       | IR     | BER   | By   |\n",
            "| 22 | EESE   | EH      |        |          | ieee | REP    |       | HESS   | HEB   | He   |\n",
            "| 23 | Haar   | SH      |        |          | GS   | ee)    |       | iu     |       | Pie  |\n",
            "| 24 |        | SE      |        |          | gee  | BE     |       | Ges    |       | EE   |\n",
            "| 25 |        | SHOES   |        |          | Gea  | RES    |       | HS     |       |      |\n",
            "| 26 |        | SHE     |        |          | Ge   | Bee    |       |        |       |      |\n",
            "| 27 |        | SH      |        |          | ue   | BS     |       |        |       |      |\n",
            "| 28 |        | SH      |        |          | GEE  | Be     |       |        |       |      |\n",
            "| 29 |        | SH      |        |          |      | BED    |       |        |       |      |\n",
            "+----+--------+---------+--------+----------+------+--------+-------+--------+-------+------+\n",
            "[INFO] saving CSV file to disk...\n"
          ]
        }
      ],
      "source": [
        "# replace NaN values with an empty string and then show a nicely\n",
        "# formatted version of our multi-column OCR'd text\n",
        "df.fillna(\"\", inplace=True)\n",
        "print(tabulate(df, headers=\"keys\", tablefmt=\"psql\"))\n",
        "# write our table to disk as a CSV file\n",
        "print(\"[INFO] saving CSV file to disk...\")\n",
        "df.to_csv(args[\"output\"], index=False)\n",
        "# show the output image after performing multi-column OCR\n",
        "cv2.imshow(\"Output\", image)\n",
        "cv2.waitKey(0)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c3cfbf57",
      "metadata": {
        "id": "c3cfbf57"
      },
      "source": [
        "# Assessing this result"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bf578bcb",
      "metadata": {
        "id": "bf578bcb"
      },
      "source": [
        "- dont want data from entire image; only below phase1: shutin period -- use regex to change where it it detects?\n",
        "- no numbers being detected, only words -- is there a setting i need to use maybe within OCR? to improve number detection over word\n",
        "- how to capture header names given that header names are sometimes in 2-3 lines; how so dont only take 1st line as the header? -- maybe use the ****** as the horizontal line dividing\n",
        "- need to assess if detecting everything (beyond quality, quantity being detected)\n",
        "- need to detect every single value in column so that aligned well compared to all columns; make sure does not skip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "60b64451",
      "metadata": {
        "id": "60b64451"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}